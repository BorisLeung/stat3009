{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-HQBcIDzaa-"
      },
      "source": [
        "# CUHK-STAT3009: Homework 1 - Basic Python, Numpy and Pandas **(due Oct 12)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y30pUb73zv4N"
      },
      "source": [
        "### Q1: Compute the **root mean squared error** of `truth` and `pred` series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vma3X__YzRNZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "truth = pd.Series(range(10))\n",
        "pred = pd.Series(range(10)) + 0.1*np.random.random(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX9k-FSJ11Q-",
        "outputId": "d690fa8d-790b-4246-a1ba-ce9e080873e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q1 solution: root mean squared error of truth and pred= 0.05287724708824683\n"
          ]
        }
      ],
      "source": [
        "## You solution here\n",
        "def rmse(truth, prediction):\n",
        "    return np.sqrt(np.mean((truth - prediction)**2))\n",
        "print(f\"Q1 solution: root mean squared error of truth and pred= {rmse(truth, pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy3_7ECJ0Kp8"
      },
      "source": [
        "### Q2: Define `mae` function\n",
        "\n",
        "Mean absolute error (MAE) is another popular metric to evaluate RS, its math formula is:\n",
        "$$\n",
        "\\text{MAE} = \\frac{1}{n} \\sum_{(u,i)} | y_{ui} - \\hat{y}_{ui} |,\n",
        "$$\n",
        "where $y_{ui}$ is the true rating, and $\\hat{y}_{ui}$ is the predicted rating.\n",
        "\n",
        "- Please define a `mae(true_rating, pred_rating)` which returns MAE for the prediction.\n",
        "- Test your function based on following code; print MAE for `rd_pred` and `pred`\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "true = np.arange(100)\n",
        "rd_pred = np.random.randn(100)\n",
        "pred = np.arange(100) + 0.1*np.random.random(100)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFKV9zdh16h5",
        "outputId": "fa6bfb39-0940-4ebb-bf09-44297c65a8cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49.54969030721789"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## You solution here\n",
        "def mae(true_rating, pred_rating):\n",
        "    return np.mean(np.abs(true_rating - pred_rating))\n",
        "\n",
        "import numpy as np\n",
        "true = np.arange(100)\n",
        "rd_pred = np.random.randn(100)\n",
        "pred = np.arange(100) + 0.1*np.random.random(100)\n",
        "mae(rd_pred, pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw0aoj1A17hM"
      },
      "source": [
        "### Q3: Numpy Array\n",
        "\n",
        "Please use Python code to address following questions.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "a = np.array([5, 10, 20, 60, 40, 90])\n",
        "b = np.array([10, 30, 40, 50, 70])\n",
        "```\n",
        "\n",
        "- Find the *union* and *intersection* of two arrays\n",
        "- Find the elements in `a` larger than 20 but smaller than 40\n",
        "- Return a bool vector, i.e. each element is True/False indicating if the corresponding element of `a` is in `b`.\n",
        "- Construct a 2D array where the first column is the first five elements of `a`, and the second column is `b`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmsbUJb-PLlD",
        "outputId": "473bc32b-ee67-4d94-97c2-8b8c3c4004d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Union of the 2 arrays: [ 5 10 20 30 40 50 60 70 90]\n",
            "\n",
            "Intersection of the 2 arrays: [10 40]\n",
            "\n",
            "Elements in a larger than 20 but smaller than 40: []\n",
            "\n",
            "bool vector indicating if the corresponding element of a is in b: [False  True False False  True False]\n",
            "\n",
            "2D array where the first column is the first five elements of a, and the second column is b: \n",
            "[[ 5 10]\n",
            " [10 30]\n",
            " [20 40]\n",
            " [60 50]\n",
            " [40 70]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## You solution here\n",
        "import numpy as np\n",
        "a = np.array([5, 10, 20, 60, 40, 90])\n",
        "b = np.array([10, 30, 40, 50, 70])\n",
        "\n",
        "print(f\"Union of the 2 arrays: {np.union1d(a, b)}\\n\")\n",
        "print(f\"Intersection of the 2 arrays: {np.intersect1d(a, b)}\\n\")\n",
        "\n",
        "print(f\"Elements in a larger than 20 but smaller than 40: {a[np.logical_and(20 < a, a < 40)]}\\n\")\n",
        "\n",
        "print(f\"bool vector indicating if the corresponding element of a is in b: {np.isin(a,b)}\\n\")\n",
        "\n",
        "print(f\"2D array where the first column is the first five elements of a, and the second column is b: \\n{np.hstack((a[:5].reshape(-1,1), b.reshape(-1,1)))}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2SBiounPyoH"
      },
      "source": [
        "### Q4: Regression\n",
        "\n",
        "Please use Python code to address following questions.\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_regression(n_samples=1000, n_features=50)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "```\n",
        "We attempt to predict `y_test` based on `X_test` and training set (`X_train`, `y_train`)\n",
        "\n",
        "Assume\n",
        "\n",
        "$$\n",
        "Y = \\mathbf{X} \\mathbf{\\beta} + e\n",
        "$$\n",
        "\n",
        "Ridge regression minimizes\n",
        "$$\n",
        "\\min_{\\beta} \\| Y - \\mathbf{X} \\mathbf{\\beta} \\|_2^2 + \\lambda \\|\\mathbf{\\beta}\\|_2^2, \\quad \\hat{\\beta} = (\\mathbf{X}^\\intercal \\mathbf{X} + \\lambda \\mathbf{I})^{-1} \\mathbf{X}^\\intercal \\mathbf{y}\n",
        "$$\n",
        "\n",
        "- Try to use `numpy.linalg.inv` to estimate $\\hat{\\beta}$ based on (`X_train`, `y_train`) for $λ = 1$, and compute mean sqaured error (MSE) for the testing set.\n",
        "\n",
        "- Try to use [`sklearn.linear_model.Ridge`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) to estimate $\\hat{\\beta}$ based on (`X_train`, `y_train`) for $λ=.5, 1, 5, 10, 100$, and compute the corresponding mean sqaured errors (MSE) for the testing set.\n",
        "\n",
        "- When $λ = 0$, the Ridge regression is reduced to Ordinary least squares (OLS). Can you compute the OLS estimator for this dataset? Dicuss potential issues of OLS.\n",
        "\n",
        "- LASSO consider the minimization:\n",
        "$$\n",
        "\\min_{\\beta} \\| Y - \\mathbf{X} \\mathbf{\\beta} \\|_2^2 + \\lambda \\|\\mathbf{\\beta}\\|_1\n",
        "$$\n",
        "Try to use [`sklearn.linear_model.Lasso`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) to estimate $\\hat{\\beta}$ based on (`X_train`, `y_train`) for $λ=.5, 1, 5, 10, 100$, and compute the corresponding mean sqaured errors (MSE) for the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smH2GVH1Ufgn",
        "outputId": "869c05c7-b0c8-466d-fc8a-3914e0e0fd91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "beta_hat=array([-2.75574240e-03,  9.59579627e+01,  5.35895044e-03,  2.23351441e-03,\n",
            "       -1.97357710e-02,  1.74637782e-02, -1.32871726e-02,  5.51418669e-03,\n",
            "        7.56436456e-03,  7.88184124e+01,  1.46067720e-02,  2.33731991e-02,\n",
            "       -2.98069766e-02, -1.59543892e-02,  1.00853948e-03,  6.32819942e-03,\n",
            "        2.91589877e+01,  5.66098087e+01, -9.95094677e-03, -5.41275236e-03,\n",
            "       -1.39657309e-02,  4.87292720e+00, -3.57148462e-02,  3.48240123e-04,\n",
            "       -9.13322434e-03, -2.01964121e-03, -3.14897853e-03,  1.54321581e-03,\n",
            "       -4.11171943e-03, -1.69324171e-03, -1.45911154e-02,  5.95841618e-03,\n",
            "       -5.03458995e-04,  1.10006397e-02, -5.51217967e-03,  9.71799917e-03,\n",
            "        6.54910873e+01,  5.51395493e-03,  2.73948184e+01,  3.79841189e-03,\n",
            "        7.34641788e+01, -2.12058101e-02, -2.71462099e-02,  1.12225970e+01,\n",
            "       -1.69851702e-02,  6.06508890e+01,  5.26672603e-03, -7.14401617e-03,\n",
            "       -1.11315429e-02,  1.27223201e-02])\n",
            "λ=1 MSE on testing set: 0.11457001957223263\n",
            "\n",
            "=========================================\n",
            "Ridge regressions:\n",
            "λ=0.5 MSE on testing set: 0.028699056040852503\n",
            "λ=0.5 𝛽̂_hat: [-1.38025909e-03  9.60393737e+01  2.68151835e-03  1.12163467e-03\n",
            " -9.88700058e-03  8.74634853e-03 -6.65544632e-03  2.76073733e-03\n",
            "  3.79058649e-03  7.88852395e+01  7.31875291e-03  1.17072878e-02\n",
            " -1.49298391e-02 -7.99111240e-03  5.07463854e-04  3.16937152e-03\n",
            "  2.91765052e+01  5.66603361e+01 -4.98083399e-03 -2.71110277e-03\n",
            " -6.99222862e-03  4.87097361e+00 -1.78880270e-02  1.73917469e-04\n",
            " -4.57652788e-03 -1.00931001e-03 -1.57613643e-03  7.73611782e-04\n",
            " -2.05808605e-03 -8.46340025e-04 -7.31104947e-03  2.98593719e-03\n",
            " -2.52660519e-04  5.51173994e-03 -2.76168640e-03  4.86628223e-03\n",
            "  6.55567987e+01  2.76104120e-03  2.74165112e+01  1.90475219e-03\n",
            "  7.35217210e+01 -1.06211286e-02 -1.35983673e-02  1.12296134e+01\n",
            " -8.50885873e-03  6.07059065e+01  2.63915571e-03 -3.57842879e-03\n",
            " -5.57442144e-03  6.37260085e-03]\n",
            "\n",
            "λ=1 MSE on testing set: 0.11457001957220272\n",
            "λ=1 𝛽̂_hat: [-2.75574240e-03  9.59579627e+01  5.35895044e-03  2.23351441e-03\n",
            " -1.97357710e-02  1.74637782e-02 -1.32871726e-02  5.51418669e-03\n",
            "  7.56436456e-03  7.88184124e+01  1.46067720e-02  2.33731991e-02\n",
            " -2.98069766e-02 -1.59543892e-02  1.00853948e-03  6.32819942e-03\n",
            "  2.91589877e+01  5.66098087e+01 -9.95094677e-03 -5.41275236e-03\n",
            " -1.39657309e-02  4.87292720e+00 -3.57148462e-02  3.48240123e-04\n",
            " -9.13322434e-03 -2.01964121e-03 -3.14897853e-03  1.54321581e-03\n",
            " -4.11171943e-03 -1.69324171e-03 -1.45911154e-02  5.95841618e-03\n",
            " -5.03458995e-04  1.10006397e-02 -5.51217967e-03  9.71799917e-03\n",
            "  6.54910873e+01  5.51395493e-03  2.73948184e+01  3.79841189e-03\n",
            "  7.34641788e+01 -2.12058101e-02 -2.71462099e-02  1.12225970e+01\n",
            " -1.69851702e-02  6.06508890e+01  5.26672603e-03 -7.14401617e-03\n",
            " -1.11315429e-02  1.27223201e-02]\n",
            "\n",
            "λ=5 MSE on testing set: 2.8196353896039965\n",
            "λ=5 𝛽̂_hat: [-1.35906930e-02  9.53121150e+01  2.66308304e-02  1.07849713e-02\n",
            " -9.71701047e-02  8.61754154e-02 -6.54989626e-02  2.72819669e-02\n",
            "  3.71597953e-02  7.82880403e+01  7.18221733e-02  1.15231256e-01\n",
            " -1.46952652e-01 -7.86724451e-02  4.79250091e-03  3.12240798e-02\n",
            "  2.90195391e+01  5.62090134e+01 -4.93276058e-02 -2.66897986e-02\n",
            " -6.90860828e-02  4.88799745e+00 -1.76155420e-01  1.75684468e-03\n",
            " -4.48845562e-02 -1.01363451e-02 -1.56135831e-02  7.55830751e-03\n",
            " -2.03812161e-02 -8.48692595e-03 -7.17338436e-02  2.92619791e-02\n",
            " -2.44392254e-03  5.41026537e-02 -2.71194829e-02  4.80128931e-02\n",
            "  6.49702511e+01  2.72478421e-02  2.72227016e+01  1.85557980e-02\n",
            "  7.30073543e+01 -1.04588506e-01 -1.33736312e-01  1.11667934e+01\n",
            " -8.36413730e-02  6.02145828e+01  2.58770643e-02 -3.52134978e-02\n",
            " -5.49729578e-02  6.27082394e-02]\n",
            "\n",
            "λ=10 MSE on testing set: 11.061557185388617\n",
            "λ=10 𝛽̂_hat: [-2.67258986e-02  9.45181479e+01  5.28498262e-02  2.06502190e-02\n",
            " -1.90667996e-01  1.69557081e-01 -1.28713720e-01  5.38540691e-02\n",
            "  7.27145738e-02  7.76355059e+01  1.40701051e-01  2.26474843e-01\n",
            " -2.88825834e-01 -1.54664028e-01  8.98528649e-03  6.14294795e-02\n",
            "  2.88469434e+01  5.57164152e+01 -9.75962341e-02 -5.24651232e-02\n",
            " -1.36347660e-01  4.90548442e+00 -3.46407855e-01  3.55007719e-03\n",
            " -8.78720232e-02 -2.03550773e-02 -3.09013062e-02  1.47345129e-02\n",
            " -4.03226961e-02 -1.70172503e-02 -1.40499045e-01  5.72386546e-02\n",
            " -4.70984360e-03  1.06017483e-01 -5.31661268e-02  9.46101504e-02\n",
            "  6.43311045e+01  5.37064000e-02  2.70110516e+01  3.60570398e-02\n",
            "  7.24449545e+01 -2.05660362e-01 -2.62613750e-01  1.10978460e+01\n",
            " -1.64156379e-01  5.96786014e+01  5.06460040e-02 -6.91948925e-02\n",
            " -1.08269544e-01  1.23216065e-01]\n",
            "\n",
            "λ=100 MSE on testing set: 805.4564719077309\n",
            "λ=100 𝛽̂_hat: [-2.05584924e-01  8.23417590e+01  4.54877875e-01  9.26017887e-02\n",
            " -1.39418602e+00  1.29248175e+00 -9.63336679e-01  4.31071575e-01\n",
            "  5.10557812e-01  6.75681047e+01  1.00328794e+00  1.69724944e+00\n",
            " -2.16522251e+00 -1.16611226e+00  1.76267117e-02  4.67294028e-01\n",
            "  2.60396395e+01  4.81805971e+01 -8.04430607e-01 -3.92268219e-01\n",
            " -1.08733159e+00  5.03268603e+00 -2.62021620e+00  3.83219498e-02\n",
            " -6.20139322e-01 -2.02105936e-01 -2.55917037e-01  9.63823328e-02\n",
            " -3.31976345e-01 -1.67195601e-01 -9.96974559e-01  3.98902270e-01\n",
            " -2.33679793e-02  7.59677164e-01 -3.83728319e-01  7.35285575e-01\n",
            "  5.46957125e+01  4.19761668e-01  2.37547915e+01  2.22589804e-01\n",
            "  6.37092863e+01 -1.55286821e+00 -1.94305336e+00  9.99146044e+00\n",
            " -1.20504413e+00  5.15157134e+01  3.55556093e-01 -5.20187563e-01\n",
            " -8.36871095e-01  9.22420144e-01]\n",
            "\n",
            "OLS 𝛽̂_hat: [ 5.64467353e-15  9.61209373e+01  3.64153152e-14 -9.05941988e-14\n",
            "  5.32907052e-14 -5.06261699e-14  9.41469125e-14  3.90798505e-14\n",
            "  1.59872116e-14  7.89521857e+01  7.10542736e-14 -1.02140518e-14\n",
            " -4.00790512e-14  1.77635684e-14  6.48370246e-14  2.84217094e-14\n",
            "  2.91940420e+01  5.67109595e+01  4.61852778e-14  1.42108547e-14\n",
            "  9.23705556e-14  4.86900423e+00 -3.37507799e-14  5.15143483e-14\n",
            " -7.10542736e-15 -2.75335310e-14  0.00000000e+00 -6.12843110e-14\n",
            " -4.08562073e-14 -1.46549439e-14  1.15463195e-14  1.59872116e-14\n",
            " -4.88498131e-14 -1.77635684e-14 -5.32907052e-14  4.79616347e-14\n",
            "  6.56226465e+01 -6.66133815e-15  2.74382440e+01 -6.92779167e-14\n",
            "  7.35793618e+01  9.68114477e-14 -8.63753513e-14  1.12366389e+01\n",
            "  1.77635684e-14  6.07610317e+01 -2.48689958e-14  5.37347944e-14\n",
            "  2.10942375e-14  2.48689958e-14]\n",
            "\n",
            "Potential issues of OLS:\n",
            "- sensitive to outliers\n",
            "- fail to address multicollinearity within the dataset.\n",
            "- assumes a normal distribution noise pattern, which might not always be the case\n",
            "\n",
            "=========================================\n",
            "Lasso regressions:\n",
            "λ=0.5 MSE on testing set: 2.7514672300004026\n",
            "λ=0.5 𝛽̂_hat: [ 0.         95.59787297  0.         -0.         -0.          0.\n",
            " -0.          0.         -0.         78.38344432 -0.          0.\n",
            " -0.         -0.         -0.          0.         28.79361057 56.14646981\n",
            " -0.         -0.         -0.          4.37738438 -0.          0.\n",
            " -0.         -0.         -0.          0.         -0.         -0.\n",
            " -0.          0.          0.          0.         -0.          0.\n",
            " 65.03148251  0.         26.91906805  0.         73.12649572 -0.\n",
            " -0.         10.68995699 -0.         60.27713898  0.         -0.\n",
            " -0.          0.        ]\n",
            "\n",
            "λ=1 MSE on testing set: 11.006545564380657\n",
            "λ=1 𝛽̂_hat: [ 0.         95.07497069  0.         -0.         -0.          0.\n",
            " -0.          0.         -0.         77.81469802 -0.          0.\n",
            " -0.         -0.         -0.          0.         28.39355814 55.58169377\n",
            " -0.         -0.         -0.          3.88539368 -0.          0.\n",
            " -0.         -0.         -0.          0.         -0.         -0.\n",
            " -0.          0.          0.          0.         -0.          0.\n",
            " 64.44030121  0.         26.39963044  0.         72.67368592 -0.\n",
            " -0.         10.14323863 -0.         59.79332027  0.         -0.\n",
            " -0.          0.        ]\n",
            "\n",
            "λ=5 MSE on testing set: 274.8712707811504\n",
            "λ=5 𝛽̂_hat: [ 0.         90.89169205  0.         -0.         -0.          0.\n",
            " -0.          0.         -0.         73.26362817 -0.          0.\n",
            " -0.         -0.         -0.          0.         25.19226597 51.06507851\n",
            " -0.         -0.         -0.          0.         -0.          0.\n",
            " -0.         -0.         -0.          0.         -0.         -0.\n",
            " -0.          0.          0.          0.         -0.          0.\n",
            " 59.70864801  0.         22.24694053  0.         69.05140381 -0.\n",
            " -0.          5.77183992 -0.         55.91786279  0.         -0.\n",
            " -0.          0.        ]\n",
            "\n",
            "λ=10 MSE on testing set: 1072.8168330811122\n",
            "λ=10 𝛽̂_hat: [ 0.         85.66875623  0.         -0.         -0.          0.\n",
            " -0.          0.         -0.         67.46517912  0.          0.\n",
            " -0.         -0.         -0.          0.         21.16040266 45.51660813\n",
            " -0.         -0.         -0.          0.         -0.          0.\n",
            " -0.         -0.         -0.          0.         -0.         -0.\n",
            " -0.          0.          0.          0.         -0.          0.\n",
            " 53.57275263  0.         17.25685016  0.         64.56254718 -0.\n",
            " -0.          0.5280232  -0.         50.6077881   0.         -0.\n",
            " -0.          0.        ]\n",
            "\n",
            "λ=100 MSE on testing set: 35733.83646052878\n",
            "λ=100 𝛽̂_hat: [-0.  0.  0. -0. -0.  0. -0.  0.  0.  0.  0.  0. -0. -0. -0.  0.  0.  0.\n",
            " -0. -0. -0.  0. -0.  0. -0. -0. -0. -0. -0. -0. -0.  0.  0.  0. -0.  0.\n",
            "  0.  0.  0. -0.  0. -0. -0.  0. -0.  0.  0. -0. -0.  0.]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Your solution here\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_regression(n_samples=1000, n_features=50)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# part 1\n",
        "def mse(truth, pred):\n",
        "    return ((truth-pred)**2).mean()\n",
        "\n",
        "lambda_ = 1\n",
        "# add ones column before X_train for linear algebra\n",
        "beta_hat = np.linalg.inv(X_train.T @ X_train + lambda_ * np.identity(X_train.shape[-1])) @ (X_train.T @ y_train)\n",
        "print(f\"{beta_hat=}\")\n",
        "print(f\"λ=1 MSE on testing set: {mse(X_test @ beta_hat, y_test)}\\n\")\n",
        "print(\"=========================================\")\n",
        "\n",
        "# part 2\n",
        "print(\"Ridge regressions:\")\n",
        "from sklearn.linear_model import Ridge\n",
        "for lam in [.5, 1, 5, 10, 100]:\n",
        "    ridge_model = Ridge(alpha = lam, fit_intercept=False)\n",
        "    ridge_model.fit(X_train, y_train)\n",
        "    print(f\"λ={lam} MSE on testing set: {mse(ridge_model.predict(X_test), y_test)}\")\n",
        "    print(f\"λ={lam} 𝛽̂_hat: {ridge_model.coef_}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "# part 3\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linear_model = LinearRegression(fit_intercept=False)\n",
        "linear_model.fit(X_train, y_train)\n",
        "print(f\"OLS 𝛽̂_hat: {linear_model.coef_}\")\n",
        "# print(f\"OLS 𝛽̂_hat: {np.linalg.inv(X_train.T @ X_train ) @ X_train.T @ y_train}\")\n",
        "print(\"\"\"\n",
        "Potential issues of OLS:\n",
        "- sensitive to outliers\n",
        "- fail to address multicollinearity within the dataset.\n",
        "- assumes a normal distribution noise pattern, which might not always be the case\n",
        "\"\"\")\n",
        "print(\"=========================================\")\n",
        "\n",
        "# part 4\n",
        "print(\"Lasso regressions:\")\n",
        "from sklearn.linear_model import Lasso\n",
        "for lam in [.5, 1, 5, 10, 100]:\n",
        "    lasso_model = Lasso(alpha = lam, fit_intercept=False)\n",
        "    lasso_model.fit(X_train, y_train)\n",
        "    print(f\"λ={lam} MSE on testing set: {mse(lasso_model.predict(X_test), y_test)}\")\n",
        "    print(f\"λ={lam} 𝛽̂_hat: {lasso_model.coef_}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIU2AtSxUjGw"
      },
      "source": [
        "### Q5: Cross-validation\n",
        "\n",
        "Please check the `nb_ml.ipynb` in the lecture about the dataset and the related methods.\n",
        "\n",
        "- Use [`sklearn.model_selection.KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) to implement 5-fold Cross-validation based on `fetch_california_housing` dataset for `kNN` regression, find the best hyperparamter and report the final performance.\n",
        "- (**Bonus**) Use [`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to implement 5-fold Cross-validation based on `fetch_california_housing` dataset for `kNN` regression, find the best hyperparamter and report the final performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pchyG5onWJtB",
        "outputId": "ded1b206-523f-4701-d4ad-e39da78a92f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "knn regression, k= 100; Test MSE avg. =  0.4739906730545899: 100%|██████████| 100/100 [02:39<00:00,  1.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5fold knn regressions MSEs:\n",
            "k =   11|  0.4161208866737139\n",
            "k =   12|  0.4162165789524662\n",
            "k =    9|  0.4166238810187166\n",
            "k =   10|  0.4167664201752388\n",
            "k =   13|  0.4173735018880941\n",
            "k =   15|  0.4182733916197492\n",
            "k =    8|  0.4184923281222065\n",
            "k =   14|  0.4186063246432106\n",
            "k =   16|  0.4186384008566953\n",
            "k =   17|  0.4189461094827315\n",
            "k =    7|  0.4196207375641198\n",
            "k =   18|  0.4201423317257501\n",
            "k =   19|  0.4215318263180013\n",
            "k =    6|  0.4219203495070042\n",
            "k =   20|  0.4226601065899430\n",
            "k =   21|  0.4237837451877308\n",
            "k =   22|  0.4245635978339511\n",
            "k =   23|  0.4255376749935763\n",
            "k =   24|  0.4271156389633504\n",
            "k =    5|  0.4278988267278248\n",
            "k =   25|  0.4289755582457989\n",
            "k =   26|  0.4299599677542870\n",
            "k =   27|  0.4306219609354975\n",
            "k =   28|  0.4313067286252509\n",
            "k =   29|  0.4320486605886272\n",
            "k =   30|  0.4328011596943318\n",
            "k =   31|  0.4335566728282633\n",
            "k =   32|  0.4346628115866932\n",
            "k =   33|  0.4356440649360783\n",
            "k =   34|  0.4363487309025044\n",
            "k =    4|  0.4363941785477921\n",
            "k =   35|  0.4368560427358453\n",
            "k =   36|  0.4379268701929933\n",
            "k =   37|  0.4388587697118272\n",
            "k =   38|  0.4392839583570701\n",
            "k =   39|  0.4396435705034515\n",
            "k =   40|  0.4400653970676046\n",
            "k =   41|  0.4406932534672521\n",
            "k =   42|  0.4412386797899208\n",
            "k =   43|  0.4417834339036278\n",
            "k =   44|  0.4425445613917814\n",
            "k =   45|  0.4434526173249750\n",
            "k =   46|  0.4443532717707528\n",
            "k =   47|  0.4452913480027936\n",
            "k =   48|  0.4461107439986344\n",
            "k =   49|  0.4466465125045906\n",
            "k =   50|  0.4469746904101134\n",
            "k =   51|  0.4476298841858789\n",
            "k =   52|  0.4482878103942260\n",
            "k =   53|  0.4488160062801961\n",
            "k =   54|  0.4492937384215508\n",
            "k =   55|  0.4499893576262036\n",
            "k =   56|  0.4507952823458049\n",
            "k =   57|  0.4514138927464537\n",
            "k =   58|  0.4519099910157377\n",
            "k =   59|  0.4524892801787700\n",
            "k =   60|  0.4531686795892841\n",
            "k =    3|  0.4534084520716298\n",
            "k =   61|  0.4536596534933199\n",
            "k =   62|  0.4542939054819380\n",
            "k =   63|  0.4548082586569928\n",
            "k =   64|  0.4554062341127544\n",
            "k =   65|  0.4559259494242774\n",
            "k =   66|  0.4564116558379247\n",
            "k =   67|  0.4567423110757663\n",
            "k =   68|  0.4571168137761725\n",
            "k =   69|  0.4575051841953637\n",
            "k =   70|  0.4582337349637413\n",
            "k =   71|  0.4587607397541515\n",
            "k =   72|  0.4591051148106733\n",
            "k =   73|  0.4596869991146022\n",
            "k =   74|  0.4602449817482269\n",
            "k =   75|  0.4608999999513575\n",
            "k =   76|  0.4613944970207425\n",
            "k =   77|  0.4620003345252431\n",
            "k =   78|  0.4623298982947172\n",
            "k =   79|  0.4630625363664228\n",
            "k =   80|  0.4637308011126372\n",
            "k =   81|  0.4643489902263516\n",
            "k =   82|  0.4648181770601582\n",
            "k =   83|  0.4654627911208601\n",
            "k =   84|  0.4660548113741740\n",
            "k =   85|  0.4666701147973907\n",
            "k =   86|  0.4671333135873984\n",
            "k =   87|  0.4676881910130099\n",
            "k =   88|  0.4681027685159782\n",
            "k =   89|  0.4685834519820811\n",
            "k =   90|  0.4688852079862472\n",
            "k =   91|  0.4693706950628403\n",
            "k =   92|  0.4697281652423282\n",
            "k =   93|  0.4702165332552055\n",
            "k =   94|  0.4708206129575054\n",
            "k =   95|  0.4713363764839630\n",
            "k =   96|  0.4718467269232789\n",
            "k =   97|  0.4723092449547652\n",
            "k =   98|  0.4728277996208920\n",
            "k =   99|  0.4734478723583748\n",
            "k =  100|  0.4739906730545899\n",
            "k =    2|  0.4908679347599889\n",
            "k =    1|  0.6427086539952289\n",
            "====================================\n",
            "Best k after 5-CV on k=[1,100]: 11\n",
            "FINAL PERFORMANCE: 5fold knn regressions MSE on test data: 0.4199418603785576\n",
            "\n",
            "====================================\n",
            "====================================\n",
            "Best params: {'n_neighbors': 11}\n",
            "FINAL PERFORMANCE: 5fold knn regressions MSE on test data: 0.4199418603785576\n"
          ]
        }
      ],
      "source": [
        "## Your solution here\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "import math\n",
        "\n",
        "california_housing = fetch_california_housing(as_frame=True)\n",
        "X, y = california_housing.data, california_housing.target\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "fold = 5\n",
        "results = []\n",
        "for k in (pbar:=tqdm(range(1,101))):\n",
        "    kf = KFold(n_splits=fold)\n",
        "    mses = []\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(X_train.copy())):\n",
        "        # print('##### %d-NN regression #####' %k)\n",
        "        neigh = KNeighborsRegressor(n_neighbors=k)\n",
        "        neigh.fit(X_train[train_index], y_train[train_index])\n",
        "\n",
        "        y_pred_train = neigh.predict(X_train[test_index])\n",
        "        mses.append(np.mean((y_pred_train - y_train[test_index])**2))\n",
        "    mean_mse = np.array(mses).mean()\n",
        "    pbar.set_description(f\"knn regression, k={k: 3}; Test MSE avg. = {mean_mse: .16f}\")\n",
        "    results.append(mean_mse)\n",
        "\n",
        "sorted = np.argsort(np.array(results))\n",
        "print(f\"{fold}fold knn regressions MSEs:\")\n",
        "for i in sorted:\n",
        "    print(f\"k = {i+1: 4}| {results[i]: .16f}\")\n",
        "print(\"====================================\")\n",
        "\n",
        "# -> Best would be k = sorted[0]; Retrain:\n",
        "best_k = sorted[0] + 1\n",
        "print(f\"Best k after 5-CV on k=[1,100]: {best_k}\")\n",
        "neigh = KNeighborsRegressor(n_neighbors=best_k)\n",
        "neigh.fit(X_train, y_train)\n",
        "y_pred_test = neigh.predict(X_test)\n",
        "print(f\"FINAL PERFORMANCE: {fold}fold knn regressions MSE on test data: {np.mean((y_pred_test - y_test)**2)}\")\n",
        "\n",
        "print()\n",
        "print(\"====================================\")\n",
        "print(\"====================================\")\n",
        "#=================BONUS====================\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "search_params = {\n",
        "    \"n_neighbors\": [i for i in range(1, 101)],\n",
        "                 }\n",
        "\n",
        "verbosity = 0\n",
        "gscv = GridSearchCV(KNeighborsRegressor(), search_params, cv=fold, scoring=\"neg_mean_squared_error\", verbose=verbosity)\n",
        "gscv.fit(X_train, y_train)\n",
        "\n",
        "# Retrain on best param:\n",
        "print(f\"Best params: {gscv.best_params_}\")\n",
        "neigh = KNeighborsRegressor(**gscv.best_params_)\n",
        "neigh.fit(X_train, y_train)\n",
        "y_pred_test = neigh.predict(X_test)\n",
        "print(f\"FINAL PERFORMANCE: {fold}fold knn regressions MSE on test data: {np.mean((y_pred_test - y_test)**2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKrMo9V2Z_Pr"
      },
      "source": [
        "### Extended Reading\n",
        "\n",
        "- [Curse of Dimensionality](https://www.kaggle.com/code/residentmario/curse-of-dimensionality/notebook)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
